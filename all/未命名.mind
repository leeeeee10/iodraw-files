{"root":{"data":{"id":"demnmynpvpc0","created":1764569372141,"text":"秋招"},"children":[{"data":{"id":"demjk7q71940","created":1764557872349,"text":"语言方面","expandState":"expand"},"children":[{"data":{"id":"demjke1f35s0","created":1764557886089,"text":"python","expandState":"expand"},"children":[{"data":{"id":"demjki9c4r40","created":1764557895275,"text":"库：调用大模型的时候用的什么库，是sdk还是openai","layout_right_offset":{"x":2,"y":-62},"expandState":"expand","note":"### OpenAI 官方 SDK (openai)\n- **安装**：`pip install openai`\n- **使用**：OpenAI 提供的官方 Python 库，用于与 GPT 系列模型进行交互。\n- **功能**：直接访问 OpenAI 提供的 GPT、DALL·E、Whisper 等模型。\n- **特点**：\n  1. 简单易用，提供封装良好的 API 调用\n  2. 需要 API 密钥进行认证\n  3. 支持调节模型参数（如温度、max tokens 等）\n\n### 自定义 SDK\n- **说明**：部分公司或组织为满足特定需求或集成场景开发的专属 SDK，例如 Hugging Face、Anthropic（Claude）、Cohere 等平台均提供自有模型的调用 SDK。\n- **特点**：\n  1. 针对特定平台定制化，支持更复杂的模型管理和训练功能\n  2. 可能需要处理更多底层细节（如模型部署、微调等）\n\n### 核心区别\n| 对比维度       | OpenAI 官方 SDK                          | 自定义 SDK                              |\n|----------------|------------------------------------------|-----------------------------------------|\n| 开发主体       | OpenAI 官方                               | 第三方平台（如 Hugging Face、Anthropic） |\n| 核心定位       | 专注自家模型调用，追求简单高效            | 适配多平台/特定场景，支持深度自定义      |\n| 使用门槛       | 低，适合快速上手                          | 较高，需了解底层细节                    |\n| 功能侧重       | 模型调用标准化，参数调节便捷              | 模型训练、部署、定制化开发              |"},"children":[]},{"data":{"id":"demjl2qho4o0","created":1764557939848,"text":"python的io了解吗","expandState":"expand","note":"io 模块常见的应用包括文件操作、内存缓冲、数据流处理等。"},"children":[]},{"data":{"id":"demjl73tzc00","created":1764557949361,"text":"描述下你项目里面的python的多线程和批次处理是如何设计的","expandState":"expand","note":"在项目中，我们需要处理上百万条数据，因此采用了多线程与批次处理结合的方式来提升吞吐量。\n\n### 核心设计要点\n#### 1. 批次处理：控制内存与任务粒度\n- 本地开发环境：每批固定 4 条，便于调试与观察日志。\n- 线上环境：批次大小根据数据量与资源动态计算（如 50/100/500 条），避免过多任务切分带来的调度开销。\n\n#### 2. 多线程：提升处理速度\n- 开发环境：固定 4 个工作线程，便于开发机资源受限时稳定运行。\n- 生产环境：线程池动态伸缩，根据 CPU 核心数和队列堆积情况自动增加或减少线程数量。\n\n### 高吞吐策略\n数据在“批次 + 多线程”的双重加速下，整体处理性能有明显提升：\n- 减少数据库连接次数\n- 降低上下文切换\n- 提高 CPU 利用率\n\n### 一句总结\n我通过批次处理提升单轮处理量，通过多线程提升并发能力，并在生产环境实现动态伸缩，使上百万级数据处理规模可以在可控时间内完成。"},"children":[]},{"data":{"id":"demjmiufx680","created":1764558053279,"text":"项目里面的生产者-消费者你是怎么设计的，描述一下这个过程","expandState":"expand","note":"### 高吞吐生产者-队列-多线程消费者流水线设计\n为处理百万级数据，通过“任务批次拆分 + 线程安全队列 + 多线程并发消费”构建稳定流水线，实现高吞吐、解耦与限流的核心目标。\n\n---\n\n#### 1. 生产者（Producer）\n- **核心职责**：数据供给与批次打包\n  - 批量从数据源读取数据（支持数据库、消息队列、文件等）\n  - 将数据按预设批次大小打包，塞入线程安全队列\n  - 动态控制生产速度，避免队列堆积溢出\n\n---\n\n#### 2. 消费者（Consumer）\n- **核心职责**：并发处理与批量输出\n  - 基于多线程模型，从队列中并发取出数据批次\n  - 执行核心业务逻辑（数据清洗、格式转换、接口调用等）\n  - 处理完成后批量写入数据库或下游系统，提升写入效率\n\n---\n\n#### 3. 队列（Queue）\n- **核心特性**：线程安全 + 缓冲限流\n  - 天然支持线程安全，避免多线程并发访问冲突\n  - 作为缓冲层，解耦生产者抓取速度与消费者处理/入库速度差异\n  - 智能限流机制：\n    - 队列满时 → 阻塞生产者，防止数据溢出\n    - 队列空时 → 阻塞消费者，等待数据供给\n\n---\n\n#### 设计优势\n1. 解耦隔离：避免入库/处理速度过慢拖垮数据抓取过程，各模块独立伸缩\n2. 高吞吐高效：多线程并发消费充分利用硬件资源，批次处理减少频繁IO开销\n3. 稳定可控：通过队列缓冲均衡整体吞吐量，避免流量峰值冲击\n4. 高可用支撑：便于扩展失败重试、数据补偿、异常监控等容错机制\n5. 资源优化：有效利用多线程并发能力，提升CPU与IO利用率"},"children":[]},{"data":{"id":"demo1iy41n40","created":1764570513403,"text":"你的消息队列是用的什么？","note":"### 队列选型：采用 Python 内置 `queue.Queue` 而非外部消息队列\n在生产者-消费者流水线中，我们未选用 Kafka、RabbitMQ 等外部消息队列系统，而是直接采用 Python 标准库内置的 **`queue.Queue`** 作为任务调度与缓冲核心，适配百万级批处理场景的需求。\n\n---\n\n#### 选型核心原因\n1. **场景适配：内部同步处理，无需跨场景传递**\n   - 任务均为单服务内部的同步批处理，无需跨进程、跨服务器或跨服务传递数据，`queue.Queue` 完全满足本地线程间通信需求。\n2. **部署轻量化：降低复杂度，随进程启停**\n   - 无需额外部署、维护外部消息队列服务，`queue.Queue` 随应用进程启动，无额外运维成本，适配单服务批处理的极简部署需求。\n3. **性能足够：线程安全+高吞吐支撑**\n   - 原生支持线程安全，无需额外封装锁机制，避免多线程并发访问冲突；\n   - 针对百万级任务吞吐场景，其缓冲与调度性能完全够用，无需过度设计。"},"children":[]},{"data":{"id":"demjlrrryuw0","created":1764557994345,"text":"项目里面你有用到tensorflow吗，具体用到了哪些请你描述一下","expandState":"expand","note":"### TensorFlow 在项目中的使用\n\n在项目中，我使用 TensorFlow 主要用于 **模型推理和数据处理任务**，具体应用如下：\n\n---\n\n#### 1. 模型加载与推理\n- 使用 `tf.saved_model.load()` 加载训练好的模型\n- 使用 `model(inputs)` 或 `model.predict()` 对批量数据进行推理\n- 对输出结果进行后处理（如分类标签映射、概率阈值筛选）\n\n```python\nimport tensorflow as tf\n\n# 加载模型\nmodel = tf.saved_model.load(\"saved_model/my_model\")\n\n# 批量推理\npredictions = model(tf.constant(batch_inputs))\n````\n\n---\n\n#### 2. 数据预处理与批次处理\n\n* 利用 `tf.data.Dataset` 构建高效数据 pipeline\n* 支持批次化（batch）、缓存（cache）和预取（prefetch）\n* 与多线程或异步 pipeline 配合，提高处理吞吐量\n\n```python\ndataset = tf.data.Dataset.from_tensor_slices(raw_data)\ndataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n```\n\n---\n\n#### 3. GPU 加速\n\n* 使用 TensorFlow 的 GPU 支持，加速大规模数据推理\n* 通过 `tf.config.list_physical_devices('GPU')` 检查可用 GPU\n* 自动在 GPU 上执行张量计算，提升性能\n\n---\n\n#### 一句话总结（面试可用）\n\n我在项目中使用 TensorFlow 加载训练好的模型进行批量数据推理，结合 `tf.data` pipeline 做高效批处理，并利用 GPU 加速，实现百万级数据的快速处理和模型推理。\n"},"children":[]},{"data":{"id":"denin57ysww0","created":1764656840833,"text":"百万级 Parquet + LLM API 多进程处理性能下降分析与优化","note":"#### 一、问题根因分析\n\n1. **性能从 40 条/s 降到 7 条/s 并卡住**\n   - **并发过高导致系统过载**\n     - 多进程参数远超服务器硬件承载（如 CPU 上下文切换激增）\n   - **API 调用未复用连接**\n     - 每次请求都新建 TCP 连接，端口逐渐耗尽\n   - **平台隐形限流**\n     - 并发超过配额时不会立即报错，而是**延迟响应** → 请求排队 → 吞吐量持续下降\n\n2. **冲高到 17 条/s 但回落并稳定到 10 条/s**\n   - 达到平台真实吞吐上限后\n   - API **动态限流机制生效**：延长响应时间以锁定吞吐量上限\n\n---\n\n#### 二、解决思路\n\n核心策略：**并发不盲拉满 → 合理匹配硬件与平台上限 → 提高单请求效率**\n\n---\n\n#### 三、具体优化措施与对应效果\n\n| 问题 | 优化措施 | 效果 |\n|------|---------|------|\n| 系统过载 | 多进程数按 CPU **1/4 核心数**配置 | 减少上下文切换，性能稳定 |\n| 端口耗尽 | 启用 **HTTP Session 连接池** | 避免资源泄露，效率翻倍 |\n| API 等待过长 | 降低超时时间/重试次数；降低 max_tokens | 降低排队与超时风险 |\n| 队列阻塞 | 增大 result queue maxsize | 避免处理线程互锁 |\n| IO 频繁 | parquet **批次增大至 500 条** | 减少数据加载开销 |\n| 单进程吞吐不足 | 每进程+线程池（2 workers） | 增加实质并行数量 |\n| 平台限流触发 | 控制活跃连接不超过**平台上限** | 长时间运行保持稳定 |\n\n---\n\n#### 四、优化后的量化结果\n\n| 项目 | 优化前 | 优化后 |\n|------|------|------|\n| 峰值吞吐 | 40 条/s | 17 条/s |\n| 稳定吞吐 | 7 条/s | **10-17 条/s 稳定运行** |\n| 内存/端口泄露 | 有 | 无 |\n| 运行时长 | 无法跑完 | 百万级数据可在可控时间内完成 |\n\n系统资源利用率：\n- CPU：70%~90% 稳定\n- 内存无累积上涨\n\n---\n\n#### 五、核心总结（面试一口气答版）\n\n**吞吐量不是并发越高越好。**  \n性能下降的根因是：**并发超硬件能力 + API 隐形限流 + TCP 连接资源泄露**。  \n我通过：\n- 限并发、稳连接、提批次\n- 单进程轻线程并行\n- 避免触发平台动态限流\n\n最终让任务吞吐量保持**长期稳定**，成功完成百万级 LLM 批量推理任务。\n\n---\n\n如面试官追问，我可以补充：\n- 队列阻塞检测与 backpressure 控制\n- LLM 请求失败自动“熔断+降级+重试”策略\n- API RTT 监控 + 指标驱动动态扩缩容机制\n\n可获得更高技术深度认可。\n"},"children":[]}]},{"data":{"id":"demjn2p2mqo0","created":1764558096490,"text":"java","expandState":"expand"},"children":[{"data":{"id":"demjn52prg00","created":1764558101669,"text":"没被问到过","expandState":"expand"},"children":[]}]},{"data":{"id":"demjn87g7c80","created":1764558108485,"text":"vue","expandState":"expand"},"children":[{"data":{"id":"demjqwoftkg0","created":1764558396848,"text":"vue3和之前版本的区别","expandState":"expand","note":"### Vue 3 与 Vue 2 的主要区别\n\nVue 3 是对 Vue 框架的重写升级版本，在性能、逻辑组织和 TypeScript 支持等方面都有显著改进。\n\n---\n\n#### 1. 核心 API 改进\n\n| 方面 | Vue 2 | Vue 3 |\n|------|-------|-------|\n| **响应式系统** | 基于 `Object.defineProperty` | 基于 Proxy，实现更完整和高效的响应式 |\n| **Composition API** | 不支持 | 支持，可用 `setup()` 组织逻辑，方便复用和组合 |\n| **Options API** | 默认使用 | 仍支持，但建议组合使用 Composition API |\n| **生命周期钩子** | `created`, `mounted` 等 | 新增 `onMounted`, `onUnmounted` 等组合式钩子 |\n| **性能** | 较好 | 重写虚拟 DOM，更快，包体积更小 |\n| **Tree Shaking** | 不支持 | 支持，按需引入减少打包体积 |\n\n---\n\n#### 2. TypeScript 支持\n\n- Vue 3 对 TypeScript 支持友好，官方声明了完整类型\n- 组件、Props、Emits 都可以完全类型推导\n- Vue 2 对 TS 支持不完善，需要第三方库补充类型\n\n---\n\n#### 3. 其他优化特性\n\n- **Fragment**：支持组件返回多个根节点\n- **Teleport**：可以将组件渲染到 DOM 的任意位置\n- **Suspense**：支持异步组件加载，提供等待占位和错误处理\n- **更小的体积**：Vue 3 核心比 Vue 2 小约 50%，渲染性能提升 2-3 倍\n- **更快的更新**：虚拟 DOM 重写、编译优化，减少不必要的组件更新\n\n---\n\n#### 4. 总结\n\nVue 3 的优势主要体现在：\n\n1. **性能提升**：Proxy 响应式 + 虚拟 DOM 重写\n2. **逻辑复用更方便**：Composition API\n3. **TypeScript 支持更好**\n4. **现代特性丰富**：Fragment, Teleport, Suspense 等\n5. **包体积更小，Tree Shaking 支持**\n\n一句话概括：\nVue 3 是对 Vue 2 的全面升级，解决了逻辑复用、性能和 TypeScript 支持的问题，同时提供了更多现代化前端特性。\n"},"children":[]}]},{"data":{"id":"demkwhrf1r40","created":1764561655671,"text":"C++","expandState":"expand"},"children":[{"data":{"id":"demkwjm3n2w0","created":1764561659703,"text":"讲一下c++的编译原理和流程","expandState":"expand","note":"### C++ 编译原理与流程\n\nC++ 的编译是一个**多阶段的过程**，涉及源代码到可执行文件的转换，每个阶段都有明确职责。\n\n---\n\n#### 1. 预处理阶段（Preprocessing）\n- 处理以 `#` 开头的指令，如：\n  - `#include`：包含头文件\n  - `#define`：宏替换\n  - 条件编译指令（`#ifdef`, `#ifndef` 等）\n- 输出结果是**纯 C++ 代码**（没有宏和头文件指令），交给编译器进行下一步\n\n```text\n源文件.cpp → 预处理 → 扩展后的源代码\n````\n\n---\n\n#### 2. 编译阶段（Compilation）\n\n* 将预处理后的源代码翻译成汇编代码（机器可读指令的中间表示）\n* 语法和语义检查：\n\n  * 类型检查\n  * 语法错误\n  * 作用域和符号解析\n* 输出 **汇编代码文件**（通常 `.s` 文件）\n\n```text\n扩展后的源代码 → 编译 → 汇编代码\n```\n\n---\n\n#### 3. 汇编阶段（Assembly）\n\n* 将汇编代码翻译成**目标文件（object file）**\n* 目标文件包含机器码和符号表，但未完成链接\n* 输出 `.o` 或 `.obj` 文件\n\n```text\n汇编代码 → 汇编器 → 目标文件(.o/.obj)\n```\n\n---\n\n#### 4. 链接阶段（Linking）\n\n* 将多个目标文件和库文件链接成可执行文件\n* 任务包括：\n\n  * 符号解析：将函数、全局变量的引用与定义匹配\n  * 地址重定位：确定各代码段和数据段在内存中的最终地址\n  * 静态库合并：如果使用了 `.lib` 或 `.a` 库\n* 输出最终可执行文件（如 `a.out` 或 `program.exe`）\n\n```text\n目标文件 + 库 → 链接器 → 可执行文件\n```\n\n---\n\n#### 5. 执行阶段（Execution）\n\n* 可执行文件被加载到内存\n* 操作系统分配运行环境\n* CPU 执行机器码\n\n---\n\n#### 6. 总结\n\nC++ 编译流程可以概括为：\n\n```text\n源代码.cpp \n    → 预处理（Preprocessing） \n    → 编译（Compilation） \n    → 汇编（Assembly） \n    → 链接（Linking） \n    → 可执行文件 → 执行\n```\n\n关键点：\n\n* 预处理：宏展开、头文件合并\n* 编译：语法分析、语义检查、生成汇编\n* 汇编：汇编 → 目标文件\n* 链接：符号解析 + 地址重定位 + 静态库整合\n* 执行：操作系统加载运行\n\n一句话总结：\nC++ 编译是从源代码到可执行文件的多阶段转化，每一阶段有明确职责，从代码解析、机器码生成，到符号链接和执行。\n\n"},"children":[]},{"data":{"id":"demkwrgci600","created":1764561676770,"text":"软连接是什么，还有什么是和他相关的","expandState":"expand","note":"### 软连接（Symbolic Link）\n\n#### 1. 定义\n- **软连接（Symbolic Link / symlink）**是一个特殊类型的文件，它包含了另一个文件或目录的路径。\n- 访问软连接时，系统会自动跳转到目标文件或目录。\n\n#### 2. 特点\n- 类似于快捷方式，而不是文件本身\n- 可以跨文件系统\n- 如果目标文件被删除或移动，软连接会失效（成为“悬挂链接”）\n- 可以对目录和文件都创建软连接\n\n#### 3. 常用命令\n```bash\n# 创建软连接\nln -s /path/to/original /path/to/link\n\n# 查看链接指向\nls -l /path/to/link\n\n# 删除软连接（不影响原文件）\nrm /path/to/link\n````\n\n#### 4. 与软连接相关的概念\n\n| 名称                                  | 定义                           | 区别                                   |\n| ----------------------------------- | ---------------------------- | ------------------------------------ |\n| **硬连接（Hard Link）**                  | 直接指向文件的 inode，相当于给同一文件创建多个名字 | 必须在同一文件系统；删除一个硬链接，文件数据仍存在；不能对目录创建硬链接 |\n| **符号链接（Symbolic Link / Soft Link）** | 文件中存储目标路径                    | 可以跨文件系统；对目录有效；目标删除后链接失效              |\n| **悬挂链接（Dangling Link）**             | 目标文件不存在的软连接                  | 访问会报错，需重新创建或删除                       |\n| **快捷方式（Windows Shortcut）**          | Windows 上的类似软连接概念            | Windows 特有，非 Linux 原生概念              |\n\n#### 5. 总结\n\n* **软连接是文件系统的一种引用方式**，通过路径指向目标文件或目录\n* 与硬连接相比，软连接更灵活，但依赖目标文件的存在\n* 常用于：\n\n  * 配置文件管理（`/etc/config`）\n  * 版本切换（`current` 指向不同版本目录）\n  * 跨目录/跨分区访问\n\n"},"children":[]}]}]},{"data":{"id":"demjnvg1ozs0","created":1764558159071,"text":"场景题","expandState":"expand"},"children":[{"data":{"id":"demjnz2uots0","created":1764558166980,"text":"图书管理系统","expandState":"expand"},"children":[{"data":{"id":"demjo3b1yvk0","created":1764558176184,"text":"一天中我发现上午10点借书的多，下午4点还书的多，怎么解决","expandState":"expand","note":"### 场景题：图书管理系统借还书高峰优化\n\n#### 背景\n- 系统架构：传统 MVC（Model-View-Controller）\n- 观察到：\n  - 上午 10 点借书高峰\n  - 下午 4 点还书高峰\n\n#### 问题\n- 高峰期请求集中，可能导致：\n  - 数据库压力大\n  - 页面响应慢\n  - 用户排队等待时间长\n\n#### 解决方案\n\n1. **借书高峰优化（上午 10 点）**\n   - **异步处理**\n     - 前端提交请求后立即响应，后端通过队列异步处理借书事务\n     - 减少前端等待时间\n   - **队列/缓存**\n     - 使用消息队列（RabbitMQ/Kafka）缓冲请求，平滑处理\n   - **数据库优化**\n     - 批量写入借书记录\n     - 使用索引优化查询\n\n2. **还书高峰优化（下午 4 点）**\n   - **自助归还/扫码**\n     - 推广自助设备，减少人工操作压力\n   - **异步更新**\n     - 后端队列异步处理还书入库，前端立即提示“归还成功”\n   - **流量引导**\n     - 提前提醒用户避开高峰时间\n     - 分散高峰负载\n\n3. **系统架构优化**\n   - **水平扩展 MVC 的 Controller**\n     - 高峰期启动多实例处理请求\n   - **缓存热点数据**\n     - 热门图书库存信息使用缓存减少数据库压力\n\n#### 总结（面试可用一句话）\n通过 **异步处理 + 消息队列 + 数据库优化 + 高峰分流**，可以缓解上午借书和下午还书的高峰压力，提高系统吞吐量和用户体验。\n"},"children":[]},{"data":{"id":"demjom9tde80","created":1764558217467,"text":"某几本书非常火，点击量非常大，怎么设计系统","expandState":"expand","note":"### 场景题：热门图书高点击量系统设计\n\n#### 背景\n- 系统：图书管理系统\n- 问题：部分图书访问量特别高，可能造成数据库压力和性能瓶颈\n\n#### 解决方案\n\n1. **缓存热点数据**\n   - 使用 **Redis/Memcached** 缓存热门图书信息（库存、借阅状态、详情等）\n   - 设置合理过期时间和更新策略（如 TTL 或主动更新）\n   - 减少数据库直接访问压力\n\n2. **异步计数与批量写入**\n   - 点击量或借阅量不需要实时写入数据库\n   - 前端请求直接更新缓存，定期批量同步到数据库\n   - 避免高并发写操作导致 DB 锁\n\n3. **读写分离**\n   - 使用 **主从数据库架构**\n     - 主库写入借阅记录\n     - 从库提供查询服务，支撑大量访问\n   - 热点查询可以直接读从库或缓存\n\n4. **CDN / 静态化处理**\n   - 图书封面、简介等静态资源通过 CDN 提供\n   - 减少应用服务器压力\n\n5. **分布式架构（可选）**\n   - 对于极端热门书籍，考虑：\n     - 独立服务或微服务部署\n     - 分片或分区存储\n\n#### 总结（面试可用一句话）\n通过 **缓存热门数据 + 异步更新 + 读写分离 + CDN 静态化**，系统能够支撑热门图书高访问量，同时保证数据库和服务器性能稳定。\n"},"children":[]},{"data":{"id":"demjovmzhns0","created":1764558237855,"text":"我发现有些时候查询书籍系统响应很慢，是哪里的问题，可以优化什么","expandState":"expand","note":"```markdown\n### 场景题：图书查询响应慢的原因与优化\n\n#### 可能原因\n\n1. **数据库性能瓶颈**\n   - 查询未加索引，导致全表扫描\n   - 热点表访问量大，锁竞争严重\n   - 大量关联查询或复杂 SQL\n\n2. **缓存缺失**\n   - 热门书籍或常用查询未缓存\n   - 每次请求都直接访问数据库\n\n3. **应用层瓶颈**\n   - Controller 或 Service 层处理逻辑复杂\n   - 并发请求过多，线程/连接池耗尽\n\n4. **网络或静态资源**\n   - 大量图片/封面未 CDN 加速\n   - 前端请求阻塞或多次重复请求\n\n---\n\n#### 优化方案\n\n1. **数据库优化**\n   - 为查询字段建立索引（如书名、作者、分类）\n   - 避免不必要的 join 和子查询\n   - 分库分表或读写分离应对高并发\n\n2. **缓存机制**\n   - 热门书籍查询结果放入 Redis/Memcached\n   - 使用 TTL 或主动更新策略\n\n3. **应用层优化**\n   - 逻辑处理异步化或批量化\n   - 连接池合理配置\n   - 使用多线程或协程提升吞吐量\n\n4. **前端和网络优化**\n   - 静态资源（封面、简介）通过 CDN 加速\n   - 前端分页或懒加载，减少一次性查询量\n\n---\n\n#### 总结（面试可用一句话）\n查询响应慢主要可能是 **数据库索引不足、缓存缺失、应用处理逻辑复杂或静态资源阻塞**，通过 **索引优化 + 缓存 + 异步/批量处理 + CDN 静态加速** 可以显著提升响应速度。\n```\n"},"children":[]}]},{"data":{"id":"demjp7e02sg0","created":1764558263433,"text":"我的项目：数据推送任务","expandState":"expand"},"children":[{"data":{"id":"demjpbtx7340","created":1764558273103,"text":"你的数据通过接口成功推送到前端展示之后，你怎么让上级收到通知","expandState":"expand","note":"### 场景题：数据成功推送后上级通知设计\n\n#### 背景\n- 系统流程：\n  1. 从 MySQL 获取数据\n  2. 构建 API 请求\n  3. 服务端处理并推送至前端展示\n- 需求：数据成功展示后，上级收到通知\n\n---\n\n#### 设计方案\n\n1. **前端确认推送状态**\n   - 前端在接收到数据并渲染成功后，向服务端发送确认接口\n   ```text\n   POST /api/acknowledge\n   body: { dataId: 123, status: \"displayed\" }\n````\n\n2. **服务端触发通知**\n\n   * 收到前端确认后，服务端通过以下方式通知上级：\n\n     * **邮件**：SMTP 发送提醒\n     * **企业 IM/消息**：如 Slack、钉钉、微信企业号\n     * **系统消息**：写入消息表，上级前端查看\n\n3. **异步处理通知**\n\n   * 使用消息队列（RabbitMQ/Kafka）将通知任务异步执行\n   * 避免阻塞主业务流程\n   * 可实现重试机制保证通知可靠\n\n4. **通知状态追踪**\n\n   * 在数据库中记录每条数据的推送状态与通知状态\n   * 可统计是否成功通知上级，便于监控\n\n---\n\n#### 总结（面试可用一句话）\n\n数据成功推送前端后，由前端回调确认，服务端异步触发消息队列发送通知（邮件/IM/系统消息），并在数据库记录状态，确保上级可靠收到提醒。\n\n"},"children":[]}]}]},{"data":{"id":"demjq0evihc0","created":1764558326613,"text":"项目描述&项目难点&如何解决","expandState":"expand"},"children":[{"data":{"id":"demjt82kicg0","created":1764558578375,"text":"AI文档校验","expandState":"expand"},"children":[{"data":{"id":"denegm6ez880","created":1764645044756,"text":"前端html你是怎么处理的"},"children":[]},{"data":{"id":"denegtw78z40","created":1764645061552,"text":"你说的这个大大减少token是怎么实现的"},"children":[]}]},{"data":{"id":"demjt924bso0","created":1764558580525,"text":"AI智能问答","expandState":"expand"},"children":[{"data":{"id":"denehcp49p40","created":1764645102483,"text":"所以我理解是你做了一个智能问答系统是吗，这是什么应用场景的"},"children":[]},{"data":{"id":"denehqfgj4w0","created":1764645132374,"text":"sse流式处理和非流式处理有什么区别"},"children":[]}]},{"data":{"id":"demjtao8z740","created":1764558584040,"text":"知识图谱","expandState":"expand"},"children":[{"data":{"id":"denehzhrs800","created":1764645152105,"text":"你这里的知识图谱是怎么用的，你给我讲一下"},"children":[]}]},{"data":{"id":"demknk7ks5s0","created":1764560955724,"text":"agent工作流","expandState":"expand"},"children":[{"data":{"id":"denei7t0lmw0","created":1764645170199,"text":"处理的是什么数据"},"children":[]},{"data":{"id":"denejrkehdc0","created":1764645291578,"text":"多模态图片数据怎么处理的？关键帧是怎么截取到的"},"children":[]},{"data":{"id":"denek0q1pgg0","created":1764645311510,"text":"关键帧截取用的什么方法，什么模型，逻辑是什么"},"children":[]}]},{"data":{"id":"demknqqyzjs0","created":1764560969958,"text":"高校成果转换平台","expandState":"expand"},"children":[{"data":{"id":"deneicni2aw0","created":1764645180750,"text":"描述一下这个项目"},"children":[]},{"data":{"id":"deneigmrns00","created":1764645189412,"text":"你有提到加密，你的明文加密怎么做的"},"children":[]},{"data":{"id":"deneimbwlf40","created":1764645201816,"text":"我还想知道你这个里面登陆的逻辑是什么"},"children":[]},{"data":{"id":"deneiw38grk0","created":1764645223060,"text":"cookie或者session是怎么设置的"},"children":[]}]},{"data":{"id":"demknx1q7zs0","created":1764560983669,"text":"就业智能体","expandState":"expand"},"children":[{"data":{"id":"demnpx078zc0","created":1764569603635,"text":"我看里面有数字人你讲一下具体有哪些模块，用的什么模型怎么实现的"},"children":[]},{"data":{"id":"deneumg8hoo0","created":1764646142448,"text":"基座模型用的什么"},"children":[]}]}]},{"data":{"id":"demjr7om0hk0","created":1764558420803,"text":"前端","expandState":"expand"},"children":[{"data":{"id":"demjrahfv400","created":1764558426900,"text":"你对跨域问题有什么了解","expandState":"expand"},"children":[]},{"data":{"id":"demjrhhn3r40","created":1764558442149,"text":"关于代理你了解多少","expandState":"expand"},"children":[]},{"data":{"id":"demjse2medk0","created":1764558513075,"text":"单点登录有做过吗","expandState":"expand"},"children":[]},{"data":{"id":"demjslaj7xs0","created":1764558528791,"text":"后端怎么和前端对接","expandState":"expand"},"children":[]},{"data":{"id":"demjssvnmf40","created":1764558545305,"text":"前端怎么做性能优化","expandState":"expand"},"children":[]},{"data":{"id":"demko9jgudc0","created":1764561010863,"text":"图片压缩你做过吗","expandState":"expand"},"children":[]},{"data":{"id":"denejdesh1k0","created":1764645260764,"text":"cookie的原理是什么？有哪些字段？和session的区别是什么？"},"children":[]}]},{"data":{"id":"demjukxvgio0","created":1764558684754,"text":"agent相关","layout_mind_offset":{"x":-9,"y":2},"expandState":"expand"},"children":[{"data":{"id":"demk6c6p4880","created":1764559606066,"text":"精调参数有哪些，你怎么设置的，为什么","expandState":"expand","note":"### 场景题：训练精参数说明与解释\n\n#### 背景\n- 基础模型：`Doubao-Seed-1.6-flash`\n- 训练方式：SFT 全量训练\n- 数据集总 Tokens：216,710,212\n- 精参数配置影响模型收敛速度、性能和训练稳定性\n\n---\n\n#### 1. 精参数及含义与作用\n\n| 参数 | 值 | 作用 | 解释 |\n|------|-----|------|------|\n| `batch_size` | 8 | 每次训练的样本数量 | 每批输入模型的数据量，影响显存占用和梯度稳定性；batch 越大，梯度越稳定，但显存需求增加 |\n| `epoch` | 2 | 全量训练循环次数 | 遍历整个训练数据集的次数；控制训练轮数，过多容易过拟合，过少可能欠拟合 |\n| `learning_rate` | 0.00001 | 学习率 | 控制权重更新幅度；SFT 微调使用小 lr 避免破坏预训练知识 |\n| `seq_len` | 32768 | 最大输入序列长度 | 模型处理的最大 token 数；保证长文本不被截断，适合大上下文任务 |\n| `freeze_llm` | false | 是否冻结 LLM 模型权重 | false 表示全量微调；true 表示冻结预训练模型，只训练头部任务层 |\n| `freeze_vit` | false | 是否冻结视觉编码器 | 任务中无视觉输入时可保持 false；如冻结则减少训练量和显存消耗 |\n| `warmup_step_rate` | 0.05 | 学习率预热比例 | 训练初期缓慢增加学习率，避免梯度震荡，稳定收敛 |\n| `最大保存模型数量` | 10 | 控制磁盘占用 | 最多保留 10 个 checkpoint，便于回滚和调参 |\n| `保存产物间隔` | 0.2 epoch | 模型保存频率 | 每 0.2 个 epoch 保存一次模型，间隔过小则过于频繁，过大可能丢失中间状态 |\n| `加密密钥` | 平台托管密钥 | 模型和数据安全 | 确保训练数据和模型产物加密，符合企业安全策略 |\n\n---\n\n#### 2. 参数设置 rationale\n\n1. **batch_size & seq_len**  \n   - 小 batch 避免显存超限，同时保证梯度稳定\n   - seq_len 大保证长文本输入完整，不丢信息\n\n2. **epoch & learning_rate**  \n   - 2 个 epoch 足够 SFT 微调收敛\n   - 超小 learning_rate 避免破坏预训练知识\n\n3. **freeze_llm / freeze_vit**  \n   - 不冻结允许全量微调，提高模型任务适应性\n   - 可根据资源和任务复杂度选择冻结\n\n4. **warmup_step_rate**  \n   - 平滑升学习率，防止初期梯度过大导致不稳定\n\n5. **保存策略 & 加密**  \n   - 保证训练过程可追溯\n   - 数据与模型安全符合平台要求\n\n---\n\n#### 总结（面试可用一句话）\n每个精参数都有明确含义：**batch_size/seq_len 决定数据输入和显存占用，epoch/learning_rate 控制收敛，freeze 决定微调范围，warmup 防止梯度震荡，保存与加密保障安全与可追溯性**，我根据任务和硬件资源合理配置，保证 SFT 微调稳定、高效。\n"},"children":[]},{"data":{"id":"demk8cdw2t40","created":1764559763229,"text":"精调的结果你怎么判断，有哪些指标，结果怎么样","expandState":"expand","note":"### 场景题：精调结果判断与指标分析\n\n#### 1. 关键指标\n\n| 指标 | 含义 | 观察与分析 |\n|------|------|------------|\n| `train/loss` | 训练损失 | 损失快速下降至接近 0，说明模型在训练集上拟合良好 |\n| `eval/loss` | 评估损失 | 与训练损失接近且稳定，表明模型在验证集上泛化正常 |\n| `num_tokens` | 输入 token 总数 | 波动稳定，无异常，数据加载正常 |\n| `num_samples` | 样本数 | 稳定，训练数据量正常 |\n| `min_tokens` / `max_tokens` | 单样本 token 范围 | 长度分布一致，未出现截断或异常 |\n| `lr` | 学习率 | 初期快速下降并逐渐稳定，符合预热 + 衰减策略 |\n| `grad_norm` | 梯度范数 | 初期较大后收敛至接近 0，参数更新稳定 |\n| `avg_loss_weight` | 损失权重均值 | 稳定接近 1，说明损失配置正常 |\n\n---\n\n#### 2. 判断模型训练结果的方法\n\n1. **损失收敛性**\n   - 训练损失和评估损失持续下降并趋于平稳\n   - 训练过程中无震荡或发散现象\n   - **结论**：模型拟合稳定，未欠拟合或过拟合\n\n2. **数据指标稳定性**\n   - token 总数、样本数、单样本长度保持稳定\n   - **结论**：数据输入正常，训练流程可靠\n\n3. **训练参数指标**\n   - 学习率按策略衰减，梯度范数收敛\n   - **结论**：训练后期参数更新稳定，梯度安全\n\n4. **辅助验证**\n   - 可在训练结束后查看任务相关指标（如准确率、召回率）\n   - 对比训练损失与评估损失差异，确保泛化能力\n\n---\n\n#### 3. 结果总结（面试可用一句话）\n\n本次精调训练过程 **稳定健康**：损失快速收敛且无波动，数据和参数指标均正常，说明模型在当前任务上拟合良好，后续可通过最终评估指标验证效果。\n"},"children":[]},{"data":{"id":"demk65d8qxs0","created":1764559591224,"text":"精调保存的多个模型选哪一个最优","expandState":"expand","note":"### 场景题：精调模型选择与多模型来源\n\n#### 1. 多个模型的来源\n- **训练过程中周期性保存**：\n  - 根据训练配置 `保存产物间隔`（如每 0.2 个 epoch 保存一次模型）\n  - 每次保存称为一个 checkpoint\n- **原因**：\n  - 训练可能中断或出现异常，可回滚到最近 checkpoint\n  - 便于后续对比不同阶段模型效果\n- **最终会产生**：\n  - 训练早期的模型（loss 高）\n  - 中期模型（loss 下降趋势）\n  - 后期模型（loss 收敛稳定）\n\n---\n\n#### 2. 如何选择最优模型\n\n1. **评估指标选择**\n   - 使用验证集（eval set）计算关键指标：\n     - 损失（`eval/loss`）\n     - 任务相关指标（如准确率、召回率、F1、BLEU、ROUGE 等）\n   - 选择在验证集上**损失最小或任务指标最优的 checkpoint**\n\n2. **稳定性考虑**\n   - 观察训练曲线，避免选择刚刚收敛但可能波动的 checkpoint\n   - 对比相邻多个 checkpoint 指标，选择最稳定且指标最优者\n\n3. **实际应用测试**\n   - 可在小规模线上或离线数据上进行推理测试\n   - 检查实际效果是否符合预期，防止过拟合\n\n---\n\n#### 3. 总结（面试可用一句话）\n训练过程中周期性保存的多个 checkpoint 提供模型回滚和对比的机会，通过 **验证集指标 + 稳定性分析 + 实际推理测试** 选择损失最小或任务指标最优的模型作为最终精调产物。\n"},"children":[]},{"data":{"id":"demk8kaqtvc0","created":1764559780453,"text":"你搭建多agent工作流的整体步骤是什么","expandState":"expand"},"children":[]},{"data":{"id":"demk5kk81xk0","created":1764559545934,"text":"你怎么优化agent的效果","expandState":"expand"},"children":[]},{"data":{"id":"demjv1du5rs0","created":1764558720547,"text":"mcp了解吗","expandState":"expand"},"children":[]},{"data":{"id":"demk8tz0f740","created":1764559801512,"text":"agent里面具体有哪些东西，分别有什么用","expandState":"expand"},"children":[]},{"data":{"id":"demnf2ce3m80","created":1764568753250,"text":"讲一下a2a协议","expandState":"expand"},"children":[]},{"data":{"id":"demnomuabu00","created":1764569503145,"text":"写调用大模型的脚本要设置哪些字段"},"children":[]},{"data":{"id":"denlyzv3pi80","created":1764666232871,"text":"分支主题"},"children":[]}]},{"data":{"id":"demjuplw8gw0","created":1764558694913,"text":"大模型算法","expandState":"expand"},"children":[{"data":{"id":"demkb3x4z480","created":1764559979895,"text":"描述一下transformer架构","expandState":"expand"},"children":[]},{"data":{"id":"demkbinnwu80","created":1764560011973,"text":"讲一下encoderonly和decoderonly","expandState":"expand"},"children":[]},{"data":{"id":"demkbpox0jk0","created":1764560027287,"text":"半监督，监督，无监督学习有什么区别，分别有什么代表的算法","expandState":"expand"},"children":[]},{"data":{"id":"demkc3eva3k0","created":1764560057154,"text":"cnn的每一层在做什么","expandState":"expand"},"children":[]},{"data":{"id":"demkc7z7aaw0","created":1764560067091,"text":"knn和kmeans聚簇有什么区别，你还用过什么别的聚簇算法","expandState":"expand"},"children":[]},{"data":{"id":"demkcqbge7k0","created":1764560107014,"text":"你怎么解决过拟合，激活函数你怎么用的","expandState":"expand"},"children":[]},{"data":{"id":"demkdomqa6g0","created":1764560181706,"text":"rnn和lstm的区别是什么，分别有什么特性","expandState":"expand"},"children":[]},{"data":{"id":"demkk0ybbsw0","created":1764560678713,"text":"pca算法有什么特性","expandState":"expand"},"children":[]},{"data":{"id":"demkkfrndb40","created":1764560710962,"text":"泊松分布和高斯分布的公式和特点","expandState":"expand"},"children":[]},{"data":{"id":"demkluyltps0","created":1764560822398,"text":"nlp是什么过程","expandState":"expand"},"children":[]},{"data":{"id":"demnem3tvqo0","created":1764568717904,"text":"描述一下kmeans的过程","expandState":"expand"},"children":[]}]},{"data":{"id":"demjus6bgpk0","created":1764558700502,"text":"手撕","expandState":"expand"},"children":[{"data":{"id":"demkf4pwuc00","created":1764560295091,"text":"二叉树反转","expandState":"expand"},"children":[]},{"data":{"id":"demkf7zszaw0","created":1764560302220,"text":"华为kmeans手撕","expandState":"expand"},"children":[]},{"data":{"id":"demkfbx3pls0","created":1764560310763,"text":"华为二叉树最大子树和","expandState":"expand"},"children":[]},{"data":{"id":"demkfjomyrc0","created":1764560327666,"text":"ip地址加.合法的话有几个ip","expandState":"expand"},"children":[]},{"data":{"id":"demkfmk6f2o0","created":1764560333926,"text":"pid和ppid kill","expandState":"expand"},"children":[]},{"data":{"id":"demkgnb92io0","created":1764560413928,"text":"循环链表，幸运儿 间隔一个淘汰","expandState":"expand"},"children":[]},{"data":{"id":"demkhxnvxiw0","created":1764560514824,"text":"找链表的交叉点  进阶考虑循环链表","expandState":"expand"},"children":[]}]},{"data":{"id":"demol2vg6ts0","created":1764572045697,"text":"HR综合"},"children":[]}]},"template":"default","theme":"fresh-blue","version":"1.4.43"}